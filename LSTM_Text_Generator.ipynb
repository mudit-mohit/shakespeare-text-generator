{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOlSzng3BEXJq3zo9fnGuI+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"baRyBbzUj-DZ","executionInfo":{"status":"ok","timestamp":1762636432914,"user_tz":-330,"elapsed":3773,"user":{"displayName":"Mudit Mohit","userId":"12136667699416304220"}},"outputId":"80e4af76-244d-4e1f-fb9a-13b878f586a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ğŸ” GITHUB PUSH - ENTER YOUR NEW TOKEN\n","==================================================\n","If you haven't created a token yet:\n","1. Go to: https://github.com/settings/tokens/new\n","2. Create token with 'repo' permissions\n","3. Copy the token and paste it below\n","==================================================\n","Paste your NEW GitHub Personal Access Token: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n","ğŸš€ Pushing to GitHub...\n","/bin/bash: -c: line 1: syntax error near unexpected token `('\n","/bin/bash: -c: line 1: `git push https://mudit-mohit:# QUICK PUSH TO FIX GITHUB NOTEBOOK - Run this entire block from google.colab import drive import os import shutil import getpass  print(\"ğŸ”„ Fixing GitHub notebook issue...\")  # Mount Google Drive drive.mount('/content/drive')  # Clone your existing repository to get the other files print(\"ğŸ“¥ Cloning your existing repository...\") !git clone https://github.com/mudit-mohit/shakespeare-text-generator.git %cd shakespeare-text-generator  # Copy your working notebook from Colab Notebooks colab_notebooks_path = \"/content/drive/MyDrive/Colab Notebooks\" notebook_name = \"LSTM Text Generator.ipynb\" notebook_path = os.path.join(colab_notebooks_path, notebook_name)  if os.path.exists(notebook_path):     # Remove the broken notebook and copy the working one     if os.path.exists(\"LSTM_Text_Generator.ipynb\"):         os.remove(\"LSTM_Text_Generator.ipynb\")          shutil.copy(notebook_path, \"LSTM_Text_Generator.ipynb\")     print(\"âœ… Replaced with working notebook from Colab\") else:     print(\"âŒ Notebook not found in Colab Notebooks\")     print(\"ğŸ“‹ Files in Colab Notebooks:\")     if os.path.exists(colab_notebooks_path):         files = os.listdir(colab_notebooks_path)         notebooks = [f for f in files if f.endswith('.ipynb')]         for nb in notebooks:             print(f\"   - {nb}\")  # Verify the notebook is valid print(\"ğŸ” Checking notebook validity...\") !python -c \"import json; json.load(open('LSTM_Text_Generator.ipynb')); print('âœ… Notebook is valid JSON')\"  # Set up Git !git config --global user.name \"mudit-mohit\" !git config --global user.email \"muditmohit@example.com\"  # CHANGE THIS  # Add and commit the fixed notebook !git add LSTM_Text_Generator.ipynb !git status !git commit -m \"fix: replace invalid notebook with working version from Colab\"  print(\"âœ… Changes committed. Ready to push...\")@github.com/mudit-mohit/shakespeare-text-generator.git main'\n","\n","ğŸ‰ SUCCESS! Your repository is now on GitHub!\n","ğŸ”— https://github.com/mudit-mohit/shakespeare-text-generator\n"]}],"source":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, Bidirectional\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","import requests\n","import re\n","from sklearn.model_selection import train_test_split\n","import random"],"metadata":{"id":"C2QjrcueIaTx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"TensorFlow version:\", tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNTdXe15vaVd","executionInfo":{"status":"ok","timestamp":1762626756125,"user_tz":-330,"elapsed":43,"user":{"displayName":"Mudit Mohit","userId":"12136667699416304220"}},"outputId":"dd619d4a-acfe-43e9-99ac-abf66a640902"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.19.0\n"]}]},{"cell_type":"code","source":["class ShakespeareTextGenerator:\n","    def __init__(self, sequence_length=40, step=3):\n","        self.sequence_length = sequence_length\n","        self.step = step\n","        self.model = None\n","        self.char_to_idx = {}\n","        self.idx_to_char = {}\n","\n","    def download_shakespeare_data(self):\n","        \"\"\"Download Shakespeare's complete works from Project Gutenberg\"\"\"\n","        print(\"Downloading Complete Shakespeare Works from Project Gutenberg...\")\n","        url = \"https://www.gutenberg.org/cache/epub/100/pg100.txt\"\n","\n","        try:\n","            response = requests.get(url, timeout=30)\n","            response.raise_for_status()\n","\n","            text = response.text\n","\n","            # Remove Gutenberg header and footer\n","            start_pattern = r\"\\*\\*\\* START OF THE PROJECT GUTENBERG EBOOK THE COMPLETE WORKS OF WILLIAM SHAKESPEARE \\*\\*\\*\"\n","            end_pattern = r\"\\*\\*\\* END OF THE PROJECT GUTENBERG EBOOK THE COMPLETE WORKS OF WILLIAM SHAKESPEARE \\*\\*\\*\"\n","\n","            start_match = re.search(start_pattern, text, re.IGNORECASE)\n","            end_match = re.search(end_pattern, text, re.IGNORECASE)\n","\n","            if start_match and end_match:\n","                text = text[start_match.end():end_match.start()]\n","\n","            self.text = text\n","            print(f\"Downloaded Complete Shakespeare: {len(self.text):,} characters\")\n","            print(f\"First 300 characters:\\n{self.text[:300]}...\\n\")\n","\n","        except Exception as e:\n","            print(f\"Download failed: {e}\")\n","            print(\"Using substantial fallback text...\")\n","            self._create_fallback_text()\n","\n","    def _create_fallback_text(self):\n","        \"\"\"Create a substantial fallback text for testing\"\"\"\n","        sample_plays = [\n","            \"To be, or not to be: that is the question: Whether 'tis nobler in the mind to suffer The slings and arrows of outrageous fortune, Or to take arms against a sea of troubles, And by opposing end them?\",\n","            \"Romeo, Romeo, wherefore art thou Romeo? Deny thy father and refuse thy name; Or, if thou wilt not, be but sworn my love, And I'll no longer be a Capulet.\",\n","            \"All the world's a stage, And all the men and women merely players: They have their exits and their entrances; And one man in his time plays many parts.\",\n","            \"Now is the winter of our discontent Made glorious summer by this sun of York; And all the clouds that lour'd upon our house In the deep bosom of the ocean buried.\",\n","            \"Shall I compare thee to a summer's day? Thou art more lovely and more temperate: Rough winds do shake the darling buds of May, And summer's lease hath all too short a date:\"\n","        ]\n","        self.text = \" \\n\".join(sample_plays * 80)\n","        print(f\"Created fallback text: {len(self.text):,} characters\")\n","\n","    def preprocess_text(self):\n","        \"\"\"Preprocess the text: lowercase and clean\"\"\"\n","        print(\"Preprocessing text...\")\n","\n","        # Convert to lowercase\n","        text = self.text.lower()\n","\n","        # Keep basic punctuation and clean up\n","        text = re.sub(r'\\n+', '\\n', text)\n","        text = re.sub(r'[ ]+', ' ', text)\n","\n","        # Get all unique characters\n","        self.chars = sorted(list(set(text)))\n","        self.vocab_size = len(self.chars)\n","\n","        print(f\"Total characters: {len(text):,}\")\n","        print(f\"Unique characters: {self.vocab_size}\")\n","        print(f\"Character set sample: {''.join(self.chars[:30])}...\")\n","\n","        # Create character to index mapping\n","        self.char_to_idx = {char: idx for idx, char in enumerate(self.chars)}\n","        self.idx_to_char = {idx: char for idx, char in enumerate(self.chars)}\n","\n","        return text\n","\n","    def create_sequences(self, text):\n","        \"\"\"Create input-output sequences for training\"\"\"\n","        print(\"Creating sequences...\")\n","\n","        # Use substantial portion of text for training\n","        training_text = text[:400000]\n","        print(f\"Using {len(training_text):,} characters for sequence creation\")\n","\n","        sentences = []\n","        next_chars = []\n","\n","        for i in range(0, len(training_text) - self.sequence_length, self.step):\n","            sentences.append(training_text[i:i + self.sequence_length])\n","            next_chars.append(training_text[i + self.sequence_length])\n","\n","        print(f\"Created {len(sentences):,} sequences\")\n","\n","        # Convert to numerical data\n","        X = np.zeros((len(sentences), self.sequence_length), dtype=np.int32)\n","        y = np.zeros((len(sentences), self.vocab_size), dtype=np.bool_)\n","\n","        for i, sentence in enumerate(sentences):\n","            for t, char in enumerate(sentence):\n","                X[i, t] = self.char_to_idx[char]\n","            y[i, self.char_to_idx[next_chars[i]]] = 1\n","\n","        return X, y\n","\n","    def build_model(self, embedding_dim=50, lstm_units=128):\n","        \"\"\"Build the basic LSTM model architecture\"\"\"\n","        print(\"Building basic LSTM model...\")\n","\n","        self.model = Sequential([\n","            Embedding(self.vocab_size, embedding_dim, input_length=self.sequence_length),\n","            LSTM(lstm_units, return_sequences=True),\n","            Dropout(0.2),\n","            LSTM(lstm_units),\n","            Dropout(0.2),\n","            Dense(self.vocab_size, activation='softmax')\n","        ])\n","\n","        self.model.compile(\n","            loss='categorical_crossentropy',\n","            optimizer=Adam(learning_rate=0.001),\n","            metrics=['accuracy']\n","        )\n","\n","        print(self.model.summary())\n","        return self.model\n","\n","    def train_model(self, X, y, epochs=30, batch_size=128):\n","        \"\"\"Train the LSTM model\"\"\"\n","        print(\"Training model...\")\n","\n","        # Split data\n","        X_train, X_val, y_train, y_val = train_test_split(\n","            X, y, test_size=0.2, random_state=42\n","        )\n","\n","        print(f\"Training on {len(X_train):,} sequences\")\n","        print(f\"Validating on {len(X_val):,} sequences\")\n","\n","        # Callbacks\n","        callbacks = [\n","            EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n","            ModelCheckpoint('basic_shakespeare_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n","        ]\n","\n","        # Train\n","        history = self.model.fit(\n","            X_train, y_train,\n","            batch_size=batch_size,\n","            epochs=epochs,\n","            validation_data=(X_val, y_val),\n","            callbacks=callbacks,\n","            verbose=1\n","        )\n","\n","        return history\n","\n","    def sample(self, preds, temperature=1.0):\n","        \"\"\"Sample from probability distribution with temperature\"\"\"\n","        preds = np.asarray(preds).astype('float64')\n","        preds = np.log(preds + 1e-8) / temperature\n","        exp_preds = np.exp(preds)\n","        preds = exp_preds / np.sum(exp_preds)\n","        probas = np.random.multinomial(1, preds, 1)\n","        return np.argmax(probas)\n","\n","    def generate_text(self, seed_text, length=400, temperature=0.7):\n","        \"\"\"Generate new text using the trained model\"\"\"\n","        if self.model is None:\n","            raise ValueError(\"Model must be trained before generating text\")\n","\n","        print(f\"Generating text with seed: '{seed_text}'...\")\n","        generated = seed_text.lower()\n","\n","        # Prepare seed\n","        if len(seed_text) < self.sequence_length:\n","            seed_text = \" \" * (self.sequence_length - len(seed_text)) + seed_text\n","        else:\n","            seed_text = seed_text[-self.sequence_length:]\n","\n","        for i in range(length):\n","            # Convert to numerical\n","            x = np.zeros((1, self.sequence_length))\n","            for t, char in enumerate(seed_text):\n","                x[0, t] = self.char_to_idx.get(char, self.char_to_idx.get(' ', 0))\n","\n","            # Predict next character\n","            preds = self.model.predict(x, verbose=0)[0]\n","            next_index = self.sample(preds, temperature)\n","            next_char = self.idx_to_char[next_index]\n","\n","            # Update\n","            generated += next_char\n","            seed_text = seed_text[1:] + next_char\n","\n","            # Show progress for long generations\n","            if i % 100 == 0:\n","                print(f\"Progress: {i}/{length} characters generated...\")\n","\n","        return self.format_generated_text(generated)\n","\n","    def format_generated_text(self, text):\n","        \"\"\"Format the generated text\"\"\"\n","        # Basic capitalization and formatting\n","        sentences = text.split('. ')\n","        sentences = [s.strip().capitalize() for s in sentences if s.strip()]\n","        text = '. '.join(sentences)\n","\n","        # Add line breaks\n","        text = text.replace('. ', '.\\n')\n","        text = text.replace('? ', '?\\n')\n","        text = text.replace('! ', '!\\n')\n","\n","        return text"],"metadata":{"id":"EDHG5A18kZcO","executionInfo":{"status":"ok","timestamp":1762626925553,"user_tz":-330,"elapsed":12,"user":{"displayName":"Mudit Mohit","userId":"12136667699416304220"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class AdvancedShakespeareGenerator:\n","    def __init__(self, sequence_length=50, step=3):\n","        self.sequence_length = sequence_length\n","        self.step = step\n","        self.model = None\n","        self.char_to_idx = {}\n","        self.idx_to_char = {}\n","\n","    def download_shakespeare_data(self):\n","        \"\"\"Download the same Project Gutenberg dataset\"\"\"\n","        print(\"Downloading Complete Shakespeare Works for Advanced Model...\")\n","        url = \"https://www.gutenberg.org/cache/epub/100/pg100.txt\"\n","\n","        try:\n","            response = requests.get(url, timeout=30)\n","            response.raise_for_status()\n","\n","            text = response.text\n","\n","            # Remove Gutenberg header and footer\n","            start_pattern = r\"\\*\\*\\* START OF THE PROJECT GUTENBERG EBOOK THE COMPLETE WORKS OF WILLIAM SHAKESPEARE \\*\\*\\*\"\n","            end_pattern = r\"\\*\\*\\* END OF THE PROJECT GUTENBERG EBOOK THE COMPLETE WORKS OF WILLIAM SHAKESPEARE \\*\\*\\*\"\n","\n","            start_match = re.search(start_pattern, text, re.IGNORECASE)\n","            end_match = re.search(end_pattern, text, re.IGNORECASE)\n","\n","            if start_match and end_match:\n","                text = text[start_match.end():end_match.start()]\n","\n","            self.text = text\n","            print(f\"Downloaded Complete Shakespeare: {len(self.text):,} characters\")\n","\n","        except Exception as e:\n","            print(f\"Download failed: {e}\")\n","            print(\"Using substantial fallback text for advanced model...\")\n","            self._create_fallback_text()\n","\n","    def _create_fallback_text(self):\n","        \"\"\"Create substantial fallback text\"\"\"\n","        sample_plays = [\n","            \"To be, or not to be: that is the question: Whether 'tis nobler in the mind to suffer The slings and arrows of outrageous fortune, Or to take arms against a sea of troubles, And by opposing end them?\",\n","            \"Romeo, Romeo, wherefore art thou Romeo? Deny thy father and refuse thy name; Or, if thou wilt not, be but sworn my love, And I'll no longer be a Capulet.\",\n","            \"All the world's a stage, And all the men and women merely players: They have their exits and their entrances; And one man in his time plays many parts.\",\n","            \"Now is the winter of our discontent Made glorious summer by this sun of York; And all the clouds that lour'd upon our house In the deep bosom of the ocean buried.\",\n","            \"Shall I compare thee to a summer's day? Thou art more lovely and more temperate: Rough winds do shake the darling buds of May, And summer's lease hath all too short a date:\"\n","        ]\n","        self.text = \" \\n\".join(sample_plays * 100)\n","        print(f\"Created advanced fallback text: {len(self.text):,} characters\")\n","\n","    def preprocess_text(self):\n","        \"\"\"Advanced preprocessing\"\"\"\n","        print(\"Advanced preprocessing...\")\n","\n","        text = self.text.lower()\n","        text = re.sub(r'\\n+', '\\n', text)\n","        text = re.sub(r'[ ]+', ' ', text)\n","\n","        self.chars = sorted(list(set(text)))\n","        self.vocab_size = len(self.chars)\n","\n","        print(f\"Total characters: {len(text):,}\")\n","        print(f\"Unique characters: {self.vocab_size}\")\n","        print(f\"Character set size: {len(self.chars)}\")\n","\n","        self.char_to_idx = {char: idx for idx, char in enumerate(self.chars)}\n","        self.idx_to_char = {idx: char for idx, char in enumerate(self.chars)}\n","\n","        return text\n","\n","    def create_sequences(self, text):\n","        \"\"\"Create sequences with larger context\"\"\"\n","        print(\"Creating sequences for advanced model...\")\n","\n","        training_text = text[:600000]\n","        print(f\"Using {len(training_text):,} characters for advanced training\")\n","\n","        sentences = []\n","        next_chars = []\n","\n","        for i in range(0, len(training_text) - self.sequence_length, self.step):\n","            sentences.append(training_text[i:i + self.sequence_length])\n","            next_chars.append(training_text[i + self.sequence_length])\n","\n","        print(f\"Created {len(sentences):,} sequences for advanced training\")\n","\n","        X = np.zeros((len(sentences), self.sequence_length), dtype=np.int32)\n","        y = np.zeros((len(sentences), self.vocab_size), dtype=np.bool_)\n","\n","        for i, sentence in enumerate(sentences):\n","            for t, char in enumerate(sentence):\n","                X[i, t] = self.char_to_idx[char]\n","            y[i, self.char_to_idx[next_chars[i]]] = 1\n","\n","        return X, y\n","\n","    def build_advanced_model(self, embedding_dim=100, lstm_units=256):\n","        \"\"\"Build advanced model with bidirectional LSTM and deeper architecture\"\"\"\n","        print(\"Building advanced LSTM model...\")\n","\n","        self.model = Sequential([\n","            Embedding(self.vocab_size, embedding_dim, input_length=self.sequence_length),\n","            Bidirectional(LSTM(lstm_units, return_sequences=True)),\n","            Dropout(0.3),\n","            LSTM(lstm_units, return_sequences=True),\n","            Dropout(0.3),\n","            LSTM(lstm_units // 2),\n","            Dropout(0.3),\n","            Dense(self.vocab_size * 2, activation='relu'),\n","            Dropout(0.2),\n","            Dense(self.vocab_size, activation='softmax')\n","        ])\n","\n","        self.model.compile(\n","            loss='categorical_crossentropy',\n","            optimizer=Adam(learning_rate=0.001),\n","            metrics=['accuracy']\n","        )\n","\n","        print(self.model.summary())\n","        return self.model\n","\n","    def train_advanced_model(self, X, y, epochs=35, batch_size=256):\n","        \"\"\"Advanced training with more callbacks\"\"\"\n","        print(\"Training advanced model...\")\n","\n","        X_train, X_val, y_train, y_val = train_test_split(\n","            X, y, test_size=0.1, random_state=42\n","        )\n","\n","        print(f\"Training on {len(X_train):,} sequences\")\n","        print(f\"Validating on {len(X_val):,} sequences\")\n","\n","        callbacks = [\n","            EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1),\n","            ModelCheckpoint('advanced_shakespeare_model.h5', monitor='val_loss', save_best_only=True, verbose=1),\n","            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0001, verbose=1)\n","        ]\n","\n","        history = self.model.fit(\n","            X_train, y_train,\n","            batch_size=batch_size,\n","            epochs=epochs,\n","            validation_data=(X_val, y_val),\n","            callbacks=callbacks,\n","            verbose=1\n","        )\n","\n","        return history\n","\n","    def sample(self, preds, temperature=1.0):\n","        \"\"\"Advanced sampling with better numerical stability\"\"\"\n","        preds = np.asarray(preds).astype('float64')\n","        preds = np.log(preds + 1e-8) / temperature\n","        exp_preds = np.exp(preds)\n","        preds = exp_preds / np.sum(exp_preds)\n","        probas = np.random.multinomial(1, preds, 1)\n","        return np.argmax(probas)\n","\n","    def generate_advanced_text(self, seed_text, length=500, temperature=0.7):\n","        \"\"\"Generate text with advanced model\"\"\"\n","        if self.model is None:\n","            raise ValueError(\"Advanced model must be trained first\")\n","\n","        print(f\"Advanced generation with seed: '{seed_text}'...\")\n","        generated = seed_text.lower()\n","\n","        if len(seed_text) < self.sequence_length:\n","            seed_text = \" \" * (self.sequence_length - len(seed_text)) + seed_text\n","        else:\n","            seed_text = seed_text[-self.sequence_length:]\n","\n","        for i in range(length):\n","            x = np.zeros((1, self.sequence_length))\n","            for t, char in enumerate(seed_text):\n","                x[0, t] = self.char_to_idx.get(char, self.char_to_idx.get(' ', 0))\n","\n","            preds = self.model.predict(x, verbose=0)[0]\n","            next_index = self.sample(preds, temperature)\n","            next_char = self.idx_to_char[next_index]\n","\n","            generated += next_char\n","            seed_text = seed_text[1:] + next_char\n","\n","            # Show progress\n","            if i % 100 == 0:\n","                print(f\"Progress: {i}/{length} characters generated...\")\n","\n","        return self.format_advanced_text(generated)\n","\n","    def format_advanced_text(self, text):\n","        \"\"\"Better formatting for advanced generation\"\"\"\n","        text = text.capitalize()\n","        text = re.sub(r'([.!?])', r'\\1 ', text)\n","        text = re.sub(r'[ ]+', ' ', text)\n","\n","        # Add line breaks for readability\n","        lines = []\n","        current_line = \"\"\n","        for word in text.split():\n","            if len(current_line + word) < 80:\n","                current_line += word + \" \"\n","            else:\n","                lines.append(current_line)\n","                current_line = word + \" \"\n","        lines.append(current_line)\n","\n","        return '\\n'.join(lines)"],"metadata":{"id":"YRhSMt3cwZeX","executionInfo":{"status":"ok","timestamp":1762627227524,"user_tz":-330,"elapsed":103,"user":{"displayName":"Mudit Mohit","userId":"12136667699416304220"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def run_basic_generator():\n","    \"\"\"Run the basic Shakespeare text generator\"\"\"\n","    print(\"=\" * 70)\n","    print(\"BASIC SHAKESPEARE TEXT GENERATOR\")\n","    print(\"USING COMPLETE PROJECT GUTENBERG DATASET\")\n","    print(\"=\" * 70)\n","\n","    # Initialize and setup\n","    generator = ShakespeareTextGenerator(sequence_length=40, step=3)\n","    generator.download_shakespeare_data()\n","    processed_text = generator.preprocess_text()\n","\n","    # Create sequences and train\n","    X, y = generator.create_sequences(processed_text)\n","    generator.build_model(embedding_dim=50, lstm_units=128)\n","\n","    print(\"\\nTraining Basic Model...\")\n","    history = generator.train_model(X, y, epochs=25, batch_size=128)\n","\n","    # Generate examples\n","    print(\"\\n\" + \"=\" * 50)\n","    print(\"BASIC MODEL GENERATED TEXT EXAMPLES\")\n","    print(\"=\" * 50)\n","\n","    seeds = [\n","        \"to be or not to be\",\n","        \"romeo romeo wherefore art thou\",\n","        \"shall i compare thee to a summer\",\n","        \"now is the winter of our discontent\"\n","    ]\n","\n","    for seed in seeds:\n","        print(f\"\\nSeed: '{seed}'\")\n","        print(\"-\" * 50)\n","        for temp in [0.3, 0.7, 1.0]:\n","            print(f\"\\nTemperature {temp}:\")\n","            generated_text = generator.generate_text(\n","                seed_text=seed,\n","                length=300,\n","                temperature=temp\n","            )\n","            print(generated_text)\n","            print(\"\\n\" + \"-\" * 40)"],"metadata":{"id":"Ji1eiHgiy1ON","executionInfo":{"status":"ok","timestamp":1762627686236,"user_tz":-330,"elapsed":49,"user":{"displayName":"Mudit Mohit","userId":"12136667699416304220"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def run_advanced_generator():\n","    \"\"\"Run the advanced Shakespeare text generator\"\"\"\n","    print(\"\\n\" + \"=\" * 70)\n","    print(\"ADVANCED SHAKESPEARE TEXT GENERATOR\")\n","    print(\"USING COMPLETE PROJECT GUTENBERG DATASET\")\n","    print(\"=\" + \"=\" * 69)\n","\n","    # Initialize advanced generator\n","    advanced_generator = AdvancedShakespeareGenerator(sequence_length=50, step=3)\n","    advanced_generator.download_shakespeare_data()\n","    processed_text = advanced_generator.preprocess_text()\n","\n","    # Create sequences and train advanced model\n","    X, y = advanced_generator.create_sequences(processed_text)\n","    advanced_generator.build_advanced_model(embedding_dim=100, lstm_units=256)\n","\n","    print(\"\\nTraining Advanced Model...\")\n","    history = advanced_generator.train_advanced_model(X, y, epochs=30, batch_size=256)\n","\n","    # Generate advanced examples\n","    print(\"\\n\" + \"=\" * 50)\n","    print(\"ADVANCED MODEL GENERATED TEXT EXAMPLES\")\n","    print(\"=\" * 50)\n","\n","    advanced_seeds = [\n","        \"to be or not to be that is the question\",\n","        \"now is the winter of our discontent made glorious\",\n","        \"shall i compare thee to a summer's day thou art\",\n","        \"romeo, romeo, wherefore art thou romeo deny thy\",\n","        \"all the world's a stage and all the men and women\"\n","    ]\n","\n","    for seed in advanced_seeds:\n","        print(f\"\\nAdvanced Seed: '{seed}'\")\n","        print(\"-\" * 60)\n","        for temp in [0.3, 0.7, 1.2]:\n","            print(f\"\\nTemperature {temp}:\")\n","            advanced_text = advanced_generator.generate_advanced_text(\n","                seed_text=seed,\n","                length=400,\n","                temperature=temp\n","            )\n","            print(advanced_text)\n","            print(\"\\n\" + \"â”€\" * 50)"],"metadata":{"id":"7NSXFVfPzIYO","executionInfo":{"status":"ok","timestamp":1762627741619,"user_tz":-330,"elapsed":5,"user":{"displayName":"Mudit Mohit","userId":"12136667699416304220"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def compare_architectures():\n","    \"\"\"Compare basic vs advanced architectures\"\"\"\n","    print(\"\\n\" + \"=\" * 70)\n","    print(\"ARCHITECTURE COMPARISON: BASIC vs ADVANCED\")\n","    print(\"=\" * 70)\n","\n","    print(\"\\nBASIC ARCHITECTURE:\")\n","    print(\"   â€¢ Single direction LSTM\")\n","    print(\"   â€¢ 2 LSTM layers (128 units each)\")\n","    print(\"   â€¢ Basic dropout (0.2)\")\n","    print(\"   â€¢ Simple embedding (50 dim)\")\n","    print(\"   â€¢ Faster training, less memory\")\n","    print(\"   â€¢ Good for quick results\")\n","\n","    print(\"\\nADVANCED ARCHITECTURE:\")\n","    print(\"   â€¢ Bidirectional LSTM\")\n","    print(\"   â€¢ 3 LSTM layers (256, 256, 128 units)\")\n","    print(\"   â€¢ Advanced dropout (0.3)\")\n","    print(\"   â€¢ Larger embedding (100 dim)\")\n","    print(\"   â€¢ Additional dense layer\")\n","    print(\"   â€¢ Learning rate scheduling\")\n","    print(\"   â€¢ Better context understanding\")\n","    print(\"   â€¢ Richer vocabulary and style\")"],"metadata":{"id":"lT0Kj2o5zWeR","executionInfo":{"status":"ok","timestamp":1762627806955,"user_tz":-330,"elapsed":20,"user":{"displayName":"Mudit Mohit","userId":"12136667699416304220"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    print(\"SHAKESPEARE TEXT GENERATOR\")\n","    print(\"Complete Project Gutenberg Dataset\")\n","    print(\"Basic and Advanced LSTM Models\")\n","    print(\"=\" * 70)\n","\n","    # Ask user which model to run\n","    print(\"\\nChoose which model to run:\")\n","    print(\"1. Basic Model Only (Faster)\")\n","    print(\"2. Advanced Model Only (Better Quality)\")\n","    print(\"3. Both Models (Complete Comparison)\")\n","\n","    try:\n","        choice = input(\"\\nEnter your choice (1/2/3): \").strip()\n","\n","        if choice == \"1\":\n","            print(\"\\n\" + \"ğŸš€\" * 20)\n","            print(\"RUNNING BASIC MODEL...\")\n","            print(\"ğŸš€\" * 20)\n","            run_basic_generator()\n","\n","        elif choice == \"2\":\n","            print(\"\\n\" + \"ğŸš€\" * 20)\n","            print(\"RUNNING ADVANCED MODEL...\")\n","            print(\"ğŸš€\" * 20)\n","            run_advanced_generator()\n","\n","        elif choice == \"3\":\n","            print(\"\\n\" + \"ğŸš€\" * 20)\n","            print(\"RUNNING BOTH MODELS - COMPLETE COMPARISON\")\n","            print(\"ğŸš€\" * 20)\n","            run_basic_generator()\n","            run_advanced_generator()\n","            compare_architectures()\n","\n","        else:\n","            print(\"Invalid choice. Running both models by default...\")\n","            run_basic_generator()\n","            run_advanced_generator()\n","            compare_architectures()\n","\n","    except KeyboardInterrupt:\n","        print(\"\\nExecution interrupted by user\")\n","    except Exception as e:\n","        print(f\"\\nError during execution: {e}\")\n","        print(\"Trying to run basic model only...\")\n","        run_basic_generator()\n","\n","    print(\"\\n\" + \"ğŸ‰\" * 20)\n","    print(\"SCRIPT EXECUTION COMPLETED!\")\n","    print(\"ğŸ‰\" * 20)\n","    print(\"\\nModel files saved:\")\n","    print(\"   â€¢ basic_shakespeare_model.h5\")\n","    print(\"   â€¢ advanced_shakespeare_model.h5\")\n","    print(\"\\nHappy Shakespearean text generating!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"r7pU4h3glmF-","executionInfo":{"status":"ok","timestamp":1762632624454,"user_tz":-330,"elapsed":2000695,"user":{"displayName":"Mudit Mohit","userId":"12136667699416304220"}},"outputId":"c5044b50-6200-4acd-de67-e8d10b97d9f9"},"execution_count":16,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["SHAKESPEARE TEXT GENERATOR\n","Complete Project Gutenberg Dataset\n","Basic and Advanced LSTM Models\n","======================================================================\n","\n","Choose which model to run:\n","1. Basic Model Only (Faster)\n","2. Advanced Model Only (Better Quality)\n","3. Both Models (Complete Comparison)\n","\n","ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€\n","RUNNING BOTH MODELS - COMPLETE COMPARISON\n","ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€\n","======================================================================\n","BASIC SHAKESPEARE TEXT GENERATOR\n","USING COMPLETE PROJECT GUTENBERG DATASET\n","======================================================================\n","Downloading Complete Shakespeare Works from Project Gutenberg...\n","Downloaded Complete Shakespeare: 5,555,374 characters\n","First 300 characters:\n","\n","\n","\n","\n","\n","The Complete Works of William Shakespeare\n","\n","by William Shakespeare\n","\n","\n","\n","\n","                    Contents\n","\n","    THE SONNETS\n","    ALLâ€™S WELL THAT ENDS WELL\n","    THE TRAGEDY OF ANTONY AND CLEOPATRA\n","    AS YOU LIKE IT\n","    THE COMEDY OF ERRORS\n","    THE TRAGEDY OF CORIOLANUS\n","    CYMBELINE\n","...\n","\n","Preprocessing text...\n","Total characters: 5,541,615\n","Unique characters: 71\n","Character set sample: \t\n"," !&'()*,-.0123456789:;?[]_a...\n","Creating sequences...\n","Using 400,000 characters for sequence creation\n","âœ… Created 133,320 sequences\n","Building basic LSTM model...\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential_4\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n","â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n","â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n","â”‚ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n","â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","</pre>\n"],"text/plain":["â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n","â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n","â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n","â”‚ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                   â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n","â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["None\n","\n","Training Basic Model...\n","Training model...\n","Training on 106,656 sequences\n","Validating on 26,664 sequences\n","Epoch 1/25\n","\u001b[1m832/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1902 - loss: 2.9919\n","Epoch 1: val_loss improved from inf to 2.28406, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.1905 - loss: 2.9907 - val_accuracy: 0.3343 - val_loss: 2.2841\n","Epoch 2/25\n","\u001b[1m831/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3437 - loss: 2.2651\n","Epoch 2: val_loss improved from 2.28406 to 2.09470, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.3437 - loss: 2.2649 - val_accuracy: 0.3867 - val_loss: 2.0947\n","Epoch 3/25\n","\u001b[1m831/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3832 - loss: 2.1120\n","Epoch 3: val_loss improved from 2.09470 to 1.97932, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.3832 - loss: 2.1118 - val_accuracy: 0.4191 - val_loss: 1.9793\n","Epoch 4/25\n","\u001b[1m830/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4125 - loss: 2.0003\n","Epoch 4: val_loss improved from 1.97932 to 1.88904, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.4125 - loss: 2.0002 - val_accuracy: 0.4438 - val_loss: 1.8890\n","Epoch 5/25\n","\u001b[1m833/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4315 - loss: 1.9226\n","Epoch 5: val_loss improved from 1.88904 to 1.82649, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.4315 - loss: 1.9225 - val_accuracy: 0.4582 - val_loss: 1.8265\n","Epoch 6/25\n","\u001b[1m830/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4491 - loss: 1.8532\n","Epoch 6: val_loss improved from 1.82649 to 1.77110, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.4491 - loss: 1.8531 - val_accuracy: 0.4740 - val_loss: 1.7711\n","Epoch 7/25\n","\u001b[1m831/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4628 - loss: 1.8083\n","Epoch 7: val_loss improved from 1.77110 to 1.72981, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.4628 - loss: 1.8083 - val_accuracy: 0.4832 - val_loss: 1.7298\n","Epoch 8/25\n","\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4743 - loss: 1.7659\n","Epoch 8: val_loss improved from 1.72981 to 1.69601, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.4743 - loss: 1.7659 - val_accuracy: 0.4925 - val_loss: 1.6960\n","Epoch 9/25\n","\u001b[1m832/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4843 - loss: 1.7266\n","Epoch 9: val_loss improved from 1.69601 to 1.66553, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.4843 - loss: 1.7266 - val_accuracy: 0.5030 - val_loss: 1.6655\n","Epoch 10/25\n","\u001b[1m829/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4920 - loss: 1.6951\n","Epoch 10: val_loss improved from 1.66553 to 1.64584, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.4920 - loss: 1.6951 - val_accuracy: 0.5049 - val_loss: 1.6458\n","Epoch 11/25\n","\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4961 - loss: 1.6798\n","Epoch 11: val_loss improved from 1.64584 to 1.62766, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.4961 - loss: 1.6798 - val_accuracy: 0.5123 - val_loss: 1.6277\n","Epoch 12/25\n","\u001b[1m830/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5004 - loss: 1.6582\n","Epoch 12: val_loss improved from 1.62766 to 1.61355, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.5004 - loss: 1.6582 - val_accuracy: 0.5134 - val_loss: 1.6135\n","Epoch 13/25\n","\u001b[1m832/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5053 - loss: 1.6323\n","Epoch 13: val_loss improved from 1.61355 to 1.60078, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5053 - loss: 1.6323 - val_accuracy: 0.5194 - val_loss: 1.6008\n","Epoch 14/25\n","\u001b[1m830/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5121 - loss: 1.6063\n","Epoch 14: val_loss improved from 1.60078 to 1.58443, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5121 - loss: 1.6063 - val_accuracy: 0.5239 - val_loss: 1.5844\n","Epoch 15/25\n","\u001b[1m832/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5145 - loss: 1.5988\n","Epoch 15: val_loss improved from 1.58443 to 1.57405, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5146 - loss: 1.5988 - val_accuracy: 0.5262 - val_loss: 1.5740\n","Epoch 16/25\n","\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5210 - loss: 1.5787\n","Epoch 16: val_loss improved from 1.57405 to 1.56633, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.5210 - loss: 1.5787 - val_accuracy: 0.5259 - val_loss: 1.5663\n","Epoch 17/25\n","\u001b[1m832/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5224 - loss: 1.5691\n","Epoch 17: val_loss improved from 1.56633 to 1.55771, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5224 - loss: 1.5691 - val_accuracy: 0.5296 - val_loss: 1.5577\n","Epoch 18/25\n","\u001b[1m833/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5275 - loss: 1.5455\n","Epoch 18: val_loss improved from 1.55771 to 1.54809, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5275 - loss: 1.5456 - val_accuracy: 0.5328 - val_loss: 1.5481\n","Epoch 19/25\n","\u001b[1m833/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5297 - loss: 1.5346\n","Epoch 19: val_loss improved from 1.54809 to 1.54637, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5297 - loss: 1.5346 - val_accuracy: 0.5320 - val_loss: 1.5464\n","Epoch 20/25\n","\u001b[1m833/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5333 - loss: 1.5294\n","Epoch 20: val_loss improved from 1.54637 to 1.53605, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.5333 - loss: 1.5294 - val_accuracy: 0.5324 - val_loss: 1.5360\n","Epoch 21/25\n","\u001b[1m829/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5360 - loss: 1.5124\n","Epoch 21: val_loss improved from 1.53605 to 1.53097, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5360 - loss: 1.5125 - val_accuracy: 0.5369 - val_loss: 1.5310\n","Epoch 22/25\n","\u001b[1m829/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5362 - loss: 1.5094\n","Epoch 22: val_loss improved from 1.53097 to 1.52779, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5362 - loss: 1.5094 - val_accuracy: 0.5377 - val_loss: 1.5278\n","Epoch 23/25\n","\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5394 - loss: 1.4966\n","Epoch 23: val_loss improved from 1.52779 to 1.52414, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5394 - loss: 1.4966 - val_accuracy: 0.5396 - val_loss: 1.5241\n","Epoch 24/25\n","\u001b[1m830/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5429 - loss: 1.4844\n","Epoch 24: val_loss improved from 1.52414 to 1.51788, saving model to basic_shakespeare_model.h5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.5429 - loss: 1.4844 - val_accuracy: 0.5396 - val_loss: 1.5179\n","Epoch 25/25\n","\u001b[1m831/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5456 - loss: 1.4798\n","Epoch 25: val_loss improved from 1.51788 to 1.51683, saving model to basic_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m834/834\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.5455 - loss: 1.4798 - val_accuracy: 0.5413 - val_loss: 1.5168\n","Restoring model weights from the end of the best epoch: 25.\n","\n","==================================================\n","BASIC MODEL GENERATED TEXT EXAMPLES\n","==================================================\n","\n","Seed: 'to be or not to be'\n","--------------------------------------------------\n","\n","Temperature 0.3:\n","Generating text with seed: 'to be or not to be'...\n","Progress: 0/300 characters generated...\n","Progress: 100/300 characters generated...\n","Progress: 200/300 characters generated...\n","To be or not to bettends.\n","\n","cleopatra.\n","o did the world to his sear be the soldier the ring of his live the strate\n","the componse the preath the forment,\n","and the doth in the man the night and heart of the soldier\n","be the dead the prace worther from not the lies\n","to his heart with is the componity and my love\n","to be\n","\n","----------------------------------------\n","\n","Temperature 0.7:\n","Generating text with seed: 'to be or not to be'...\n","Progress: 0/300 characters generated...\n","Progress: 100/300 characters generated...\n","Progress: 200/300 characters generated...\n","To be or not to bett\n","such burding of beauty not a the reads of you,\n","of that the countest then when me which but our his boy,\n","is i did that their a have all all if i am is surpent,\n","this the court heart of good some see\n","shall your say constration fair the peaconce.\n","shall and singlos upon the true of the doodself\n","\n","----------------------------------------\n","\n","Temperature 1.0:\n","Generating text with seed: 'to be or not to be'...\n","Progress: 0/300 characters generated...\n","Progress: 100/300 characters generated...\n","Progress: 200/300 characters generated...\n","To be or not to beauty!\n","which i for your from mind, seick dispatten, so\n","of his the honour; know who countess me.\n","Thee hath prian!\n","\n","mardian.\n","when this is shot be) no can that that dissord.\n","\n","harghes._]\n","\n","enobarbus.\n","she other simpess in thine\n","to be with dices deasce.\n","Thy great is me will puss dears in milraen,\n","\n","----------------------------------------\n","\n","Seed: 'romeo romeo wherefore art thou'\n","--------------------------------------------------\n","\n","Temperature 0.3:\n","Generating text with seed: 'romeo romeo wherefore art thou'...\n","Progress: 0/300 characters generated...\n","Progress: 100/300 characters generated...\n","Progress: 200/300 characters generated...\n","Romeo romeo wherefore art thou hard of the florents\n","but that i will the world his see the forest\n","would the live and i shall the hands of the right,\n","and the countess of the compon the countess mears with his seem not and some strength\n","his seem to the pringe and and with the parted the soldier.\n","\n","cleopatra.\n","what he shall the\n","\n","----------------------------------------\n","\n","Temperature 0.7:\n","Generating text with seed: 'romeo romeo wherefore art thou'...\n","Progress: 0/300 characters generated...\n","Progress: 100/300 characters generated...\n","Progress: 200/300 characters generated...\n","Romeo romeo wherefore art thought,\n","which im not my letter thy as by dur.\n","\n","cleopatra.\n","no hor of the court.\n","\n","antony.\n","when i would i could not hine every with should\n","to the countes of i wishell of for the stripbe\n","by the world with a preculite but will with\n","provelles, and men the trundines, and there and mad\n","so do hours o\n","\n","----------------------------------------\n","\n","Temperature 1.0:\n","Generating text with seed: 'romeo romeo wherefore art thou'...\n","Progress: 0/300 characters generated...\n","Progress: 100/300 characters generated...\n","Progress: 200/300 characters generated...\n","Romeo romeo wherefore art thought,\n","befoll love, conded with be sick weal spit far hers great\n","and speak and hartes if that you be should\n","never with player for no day, tormiger?\n","pray,\n","infonsing five, but but nay minembuse,\n","with hour is be minglyâ€™s than in such on whent;\n","out love, thou andser off aftients, and kept.\n","\n","paroll\n","\n","----------------------------------------\n","\n","Seed: 'shall i compare thee to a summer'\n","--------------------------------------------------\n","\n","Temperature 0.3:\n","Generating text with seed: 'shall i compare thee to a summer'...\n","Progress: 0/300 characters generated...\n","Progress: 100/300 characters generated...\n","Progress: 200/300 characters generated...\n","Shall i compare thee to a summer.\n","\n","cleopatra.\n","i the greater that i have shall the right\n","the have shall the court for the have the dids\n","and the countess to the forest the part the griend\n","with the forming that i have the greatert and the compant,\n","and the court of his have the countess so the right\n","but the world the compons i\n","\n","----------------------------------------\n","\n","Temperature 0.7:\n","Generating text with seed: 'shall i compare thee to a summer'...\n","Progress: 0/300 characters generated...\n","Progress: 100/300 characters generated...\n","Progress: 200/300 characters generated...\n","Shall i compare thee to a summer\n","to good hear.\n","\n","countess.\n","his never with the man mind and peince it\n","for meen their manst and letten and so.\n","the hade to the lasime sision the honour what.\n","\n"," enter antony be to sonder.\n","\n","cleopatra.\n","not lead does for my fill.\n","\n","menas.\n","his here, i therean fealts\n","the prove, and romes thou d\n","\n","----------------------------------------\n","\n","Temperature 1.0:\n","Generating text with seed: 'shall i compare thee to a summer'...\n","Progress: 0/300 characters generated...\n","Progress: 100/300 characters generated...\n","Progress: 200/300 characters generated...\n","Shall i compare thee to a summer\n","on my love well?\n","\n","bertram.\n","he sweet i would, master of i dram love but thy wide jeauty, tires him you,\n","for my sqiron asseing, and with thou will: me berorion not\n","as endest cemand words.\n","\n"," [_exeunt._]\n","\n","scene iv.\n","Another he to the lord you.\n","But the resine,\n","mine bother ganses with yous mero\n","\n","----------------------------------------\n","\n","Seed: 'now is the winter of our discontent'\n","--------------------------------------------------\n","\n","Temperature 0.3:\n","Generating text with seed: 'now is the winter of our discontent'...\n","Progress: 0/300 characters generated...\n","Progress: 100/300 characters generated...\n","Progress: 200/300 characters generated...\n","Now is the winter of our discontent,\n","the countess of the fulves would heart compant with the love that the fores,\n","my sonse to the pompey of the world to shall to heart\n","which i have the sing to the love the dead of the waste\n","in the componse the love the fores and heart\n","and the praise the countess to the world\n","the countess and th\n","\n","----------------------------------------\n","\n","Temperature 0.7:\n","Generating text with seed: 'now is the winter of our discontent'...\n","Progress: 0/300 characters generated...\n","Progress: 100/300 characters generated...\n","Progress: 200/300 characters generated...\n","Now is the winter of our discontent\n","with praise of portence strite of my grow,\n","and the ruvery all strange of me you as mad wants of you,\n","and what thou art best you the beaun to his army,\n","make in the pause on sweet of the eary mad\n","to mund his seed untures of countess bound of mind\n","he profied in alexas!\n","sir, which our in my comfe\n","\n","----------------------------------------\n","\n","Temperature 1.0:\n","Generating text with seed: 'now is the winter of our discontent'...\n","Progress: 0/300 characters generated...\n","Progress: 100/300 characters generated...\n","Progress: 200/300 characters generated...\n","Now is the winter of our discontent.\n","to suiting to marls, arais, it is you,\n","a grestelf from.\n","O thou and not?\n","\n","cleriana.\n","my done of the dine to madring, on â€œure loveâ€™s thourf,\n","she your whereself birdned may this think blood!\n","shall not more too kept.\n","\n","first dives.\n","what she not.\n","\n","lafew.\n","you good trueâ€™s meater phe fareresty\n","\n","----------------------------------------\n","\n","======================================================================\n","ADVANCED SHAKESPEARE TEXT GENERATOR\n","USING COMPLETE PROJECT GUTENBERG DATASET\n","======================================================================\n","Downloading Complete Shakespeare Works for Advanced Model...\n","Downloaded Complete Shakespeare: 5,555,374 characters\n","Advanced preprocessing...\n","Total characters: 5,541,615\n","Unique characters: 71\n","Character set size: 71\n","Creating sequences for advanced model...\n","Using 600,000 characters for advanced training\n","Created 199,984 sequences for advanced training\n","Building advanced LSTM model...\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_5\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n","â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n","â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n","â”‚ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)                  â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)                  â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n","â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n","â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n","â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n","â”‚ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n","â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["None\n","\n","Training Advanced Model...\n","Training advanced model...\n","Training on 179,985 sequences\n","Validating on 19,999 sequences\n","Epoch 1/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.1808 - loss: 3.0028\n","Epoch 1: val_loss improved from inf to 2.28305, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 64ms/step - accuracy: 0.1810 - loss: 3.0018 - val_accuracy: 0.3315 - val_loss: 2.2830 - learning_rate: 0.0010\n","Epoch 2/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.3328 - loss: 2.2786\n","Epoch 2: val_loss improved from 2.28305 to 2.07401, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.3328 - loss: 2.2785 - val_accuracy: 0.3898 - val_loss: 2.0740 - learning_rate: 0.0010\n","Epoch 3/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.3815 - loss: 2.1018\n","Epoch 3: val_loss improved from 2.07401 to 1.93125, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 64ms/step - accuracy: 0.3816 - loss: 2.1017 - val_accuracy: 0.4208 - val_loss: 1.9313 - learning_rate: 0.0010\n","Epoch 4/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.4159 - loss: 1.9746\n","Epoch 4: val_loss improved from 1.93125 to 1.83204, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.4160 - loss: 1.9746 - val_accuracy: 0.4524 - val_loss: 1.8320 - learning_rate: 0.0010\n","Epoch 5/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.4364 - loss: 1.8942\n","Epoch 5: val_loss improved from 1.83204 to 1.76690, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.4364 - loss: 1.8941 - val_accuracy: 0.4693 - val_loss: 1.7669 - learning_rate: 0.0010\n","Epoch 6/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.4557 - loss: 1.8264\n","Epoch 6: val_loss improved from 1.76690 to 1.70957, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.4557 - loss: 1.8264 - val_accuracy: 0.4820 - val_loss: 1.7096 - learning_rate: 0.0010\n","Epoch 7/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.4690 - loss: 1.7743\n","Epoch 7: val_loss improved from 1.70957 to 1.66781, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 64ms/step - accuracy: 0.4690 - loss: 1.7743 - val_accuracy: 0.4904 - val_loss: 1.6678 - learning_rate: 0.0010\n","Epoch 8/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.4814 - loss: 1.7280\n","Epoch 8: val_loss improved from 1.66781 to 1.63341, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.4814 - loss: 1.7280 - val_accuracy: 0.5016 - val_loss: 1.6334 - learning_rate: 0.0010\n","Epoch 9/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.4870 - loss: 1.7005\n","Epoch 9: val_loss improved from 1.63341 to 1.61095, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.4870 - loss: 1.7005 - val_accuracy: 0.5107 - val_loss: 1.6109 - learning_rate: 0.0010\n","Epoch 10/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.4950 - loss: 1.6702\n","Epoch 10: val_loss improved from 1.61095 to 1.58177, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 64ms/step - accuracy: 0.4950 - loss: 1.6701 - val_accuracy: 0.5177 - val_loss: 1.5818 - learning_rate: 0.0010\n","Epoch 11/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.4993 - loss: 1.6441\n","Epoch 11: val_loss improved from 1.58177 to 1.56978, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.4993 - loss: 1.6441 - val_accuracy: 0.5201 - val_loss: 1.5698 - learning_rate: 0.0010\n","Epoch 12/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5085 - loss: 1.6159\n","Epoch 12: val_loss improved from 1.56978 to 1.55377, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 64ms/step - accuracy: 0.5085 - loss: 1.6159 - val_accuracy: 0.5239 - val_loss: 1.5538 - learning_rate: 0.0010\n","Epoch 13/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5128 - loss: 1.5997\n","Epoch 13: val_loss improved from 1.55377 to 1.54386, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.5128 - loss: 1.5997 - val_accuracy: 0.5270 - val_loss: 1.5439 - learning_rate: 0.0010\n","Epoch 14/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5173 - loss: 1.5833\n","Epoch 14: val_loss improved from 1.54386 to 1.53054, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.5173 - loss: 1.5833 - val_accuracy: 0.5313 - val_loss: 1.5305 - learning_rate: 0.0010\n","Epoch 15/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5223 - loss: 1.5618\n","Epoch 15: val_loss improved from 1.53054 to 1.52544, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.5223 - loss: 1.5618 - val_accuracy: 0.5338 - val_loss: 1.5254 - learning_rate: 0.0010\n","Epoch 16/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5268 - loss: 1.5456\n","Epoch 16: val_loss improved from 1.52544 to 1.51253, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 64ms/step - accuracy: 0.5268 - loss: 1.5456 - val_accuracy: 0.5373 - val_loss: 1.5125 - learning_rate: 0.0010\n","Epoch 17/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5319 - loss: 1.5306\n","Epoch 17: val_loss improved from 1.51253 to 1.50543, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 64ms/step - accuracy: 0.5319 - loss: 1.5306 - val_accuracy: 0.5410 - val_loss: 1.5054 - learning_rate: 0.0010\n","Epoch 18/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5333 - loss: 1.5172\n","Epoch 18: val_loss improved from 1.50543 to 1.50169, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.5333 - loss: 1.5172 - val_accuracy: 0.5405 - val_loss: 1.5017 - learning_rate: 0.0010\n","Epoch 19/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5371 - loss: 1.5010\n","Epoch 19: val_loss improved from 1.50169 to 1.49284, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 64ms/step - accuracy: 0.5371 - loss: 1.5010 - val_accuracy: 0.5442 - val_loss: 1.4928 - learning_rate: 0.0010\n","Epoch 20/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5384 - loss: 1.4986\n","Epoch 20: val_loss did not improve from 1.49284\n","\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.5384 - loss: 1.4986 - val_accuracy: 0.5461 - val_loss: 1.4948 - learning_rate: 0.0010\n","Epoch 21/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5435 - loss: 1.4810\n","Epoch 21: val_loss improved from 1.49284 to 1.48397, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 64ms/step - accuracy: 0.5435 - loss: 1.4810 - val_accuracy: 0.5467 - val_loss: 1.4840 - learning_rate: 0.0010\n","Epoch 22/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5447 - loss: 1.4693\n","Epoch 22: val_loss did not improve from 1.48397\n","\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 63ms/step - accuracy: 0.5447 - loss: 1.4693 - val_accuracy: 0.5457 - val_loss: 1.4893 - learning_rate: 0.0010\n","Epoch 23/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5491 - loss: 1.4625\n","Epoch 23: val_loss improved from 1.48397 to 1.47977, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 64ms/step - accuracy: 0.5491 - loss: 1.4624 - val_accuracy: 0.5517 - val_loss: 1.4798 - learning_rate: 0.0010\n","Epoch 24/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5533 - loss: 1.4443\n","Epoch 24: val_loss improved from 1.47977 to 1.47231, saving model to advanced_shakespeare_model.h5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.5533 - loss: 1.4443 - val_accuracy: 0.5512 - val_loss: 1.4723 - learning_rate: 0.0010\n","Epoch 25/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5535 - loss: 1.4409\n","Epoch 25: val_loss did not improve from 1.47231\n","\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.5535 - loss: 1.4409 - val_accuracy: 0.5545 - val_loss: 1.4742 - learning_rate: 0.0010\n","Epoch 26/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5593 - loss: 1.4230\n","Epoch 26: val_loss did not improve from 1.47231\n","\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.5593 - loss: 1.4230 - val_accuracy: 0.5521 - val_loss: 1.4796 - learning_rate: 0.0010\n","Epoch 27/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5572 - loss: 1.4187\n","Epoch 27: val_loss did not improve from 1.47231\n","\n","Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.5572 - loss: 1.4187 - val_accuracy: 0.5536 - val_loss: 1.4789 - learning_rate: 0.0010\n","Epoch 28/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5665 - loss: 1.3938\n","Epoch 28: val_loss did not improve from 1.47231\n","\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.5665 - loss: 1.3938 - val_accuracy: 0.5558 - val_loss: 1.4756 - learning_rate: 5.0000e-04\n","Epoch 29/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5699 - loss: 1.3733\n","Epoch 29: val_loss did not improve from 1.47231\n","\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 64ms/step - accuracy: 0.5699 - loss: 1.3733 - val_accuracy: 0.5579 - val_loss: 1.4761 - learning_rate: 5.0000e-04\n","Epoch 30/30\n","\u001b[1m703/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5727 - loss: 1.3657\n","Epoch 30: val_loss did not improve from 1.47231\n","\n","Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\u001b[1m704/704\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 63ms/step - accuracy: 0.5727 - loss: 1.3657 - val_accuracy: 0.5585 - val_loss: 1.4727 - learning_rate: 5.0000e-04\n","Restoring model weights from the end of the best epoch: 24.\n","\n","==================================================\n","ADVANCED MODEL GENERATED TEXT EXAMPLES\n","==================================================\n","\n","Advanced Seed: 'to be or not to be that is the question'\n","------------------------------------------------------------\n","\n","Temperature 0.3:\n","Advanced generation with seed: 'to be or not to be that is the question'...\n","Progress: 0/400 characters generated...\n","Progress: 100/400 characters generated...\n","Progress: 200/400 characters generated...\n","Progress: 300/400 characters generated...\n","To be or not to be that is the question, the state that which the noint of i \n","shall that a come, and speak the hand me that i will say the shame, no has my \n","heart the best that to see the hast and the mine into the son my will like, \n","that he man your that that that i so be should the love, the sum me made my \n","breath and my spare the prince when this hast a thank and with my act in \n","beauty, and the world that my dear the man that is \n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","Temperature 0.7:\n","Advanced generation with seed: 'to be or not to be that is the question'...\n","Progress: 0/400 characters generated...\n","Progress: 100/400 characters generated...\n","Progress: 200/400 characters generated...\n","Progress: 300/400 characters generated...\n","To be or not to be that is the question. first diess. i know or indeed me. \n","enter caesar, a rare. antony. in will to him in bue earths thou was my sit, and \n","love his taledy have well that that not. what, i stay thy heart, lord like \n","ofter me, with better detain, for when that thus sholder for you aming. notâ€™st \n","him. [_siess enobarbus. _] enter caesar, for my to should heart and good gruel. \n","yet shill desire trust pr \n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","Temperature 1.2:\n","Advanced generation with seed: 'to be or not to be that is the question'...\n","Progress: 0/400 characters generated...\n","Progress: 100/400 characters generated...\n","Progress: 200/400 characters generated...\n","Progress: 300/400 characters generated...\n","To be or not to be that is the question, she now which away, i saw charmian. \n","charmian. to no jome; no altay commible at this sharg in hieing of love bed? it \n","my name phoilia that griss and midry in lemp. with thlage. ting, sine them. \n","rosalind. alay, to burn. caesar. catent. though, a wiunder man are yate, whâ€™ \n","are hine must the haves overake tahe, in his hase and you mislellek servied, \n","betwear abuke shame: o beheld \n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","Advanced Seed: 'now is the winter of our discontent made glorious'\n","------------------------------------------------------------\n","\n","Temperature 0.3:\n","Advanced generation with seed: 'now is the winter of our discontent made glorious'...\n","Progress: 0/400 characters generated...\n","Progress: 100/400 characters generated...\n","Progress: 200/400 characters generated...\n","Progress: 300/400 characters generated...\n","Now is the winter of our discontent made glorious way a love, i love in this \n","some that the wife a man for the hours, the shame her hand my wit which the art \n","the most better heart, and have made and man that the that the will, and that \n","the beauty of a can the man the tount. antony. i sing the brother, the sound of \n","your hand, therefore he love the deserve the way, i shall shall since the can \n","an thee man the brain, the man the content to \n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","Temperature 0.7:\n","Advanced generation with seed: 'now is the winter of our discontent made glorious'...\n","Progress: 0/400 characters generated...\n","Progress: 100/400 characters generated...\n","Progress: 200/400 characters generated...\n","Progress: 300/400 characters generated...\n","Now is the winter of our discontent made glorious to like, then for an nebare \n","vilsure worthy not. cleopatra. marry, the live a should can marry, come my \n","harbry how should she falls is praised, and mine counted. countess. have \n","fainting but my pleasure, though the love. orlando. yes, if as the hold left \n","will me, old with him sure, a wit, the uselved be amperence worrable of all so \n","be do apped thou made for the expesty pove sent any \n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","Temperature 1.2:\n","Advanced generation with seed: 'now is the winter of our discontent made glorious'...\n","Progress: 0/400 characters generated...\n","Progress: 100/400 characters generated...\n","Progress: 200/400 characters generated...\n","Progress: 300/400 characters generated...\n","Now is the winter of our discontent made glorious. day. layst to to him? \n","officus of ephesus. yuch will husband, no. orlando. i dantion. henour this \n","uchang, and one is. [_exit. _] scene vacus. would many hove you melestion \n","dicheje, shill we bietier unserbreges missomanâ€™d are for out eozen his gubt on \n","than thirnmal. your lateger brayed to stose, eno in defurt, stroman exportkly \n","lookry todayâ€_ when gration you, if lame as wo \n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","Advanced Seed: 'shall i compare thee to a summer's day thou art'\n","------------------------------------------------------------\n","\n","Temperature 0.3:\n","Advanced generation with seed: 'shall i compare thee to a summer's day thou art'...\n","Progress: 0/400 characters generated...\n","Progress: 100/400 characters generated...\n","Progress: 200/400 characters generated...\n","Progress: 300/400 characters generated...\n","Shall i compare thee to a summer's day thou art the hand. parolles. the wite \n","the world that heard the wit, the wast in it say that what acque i have stand \n","which make the most hand of the many man that i shall have will me, i have \n","caesar say when the some messenger. cleopatra. i shall shall marry, sir, the \n","hating the comport, my steel have me in the tount that better some not makes \n","not him, the world in the world the hand the shoul \n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","Temperature 0.7:\n","Advanced generation with seed: 'shall i compare thee to a summer's day thou art'...\n","Progress: 0/400 characters generated...\n","Progress: 100/400 characters generated...\n","Progress: 200/400 characters generated...\n","Progress: 300/400 characters generated...\n","Shall i compare thee to a summer's day thou art that here here reserve a her \n","true i denity, and for him peaning most oftent thee that which my made with \n","him. bertram. no persivous ends no lips and when this, sarewhers. dromio of \n","syracuse. four all will thou many prequers a servire more sin. antony. \n","court-will to my shall perple caesar, sir, shall not, and i have did word of a \n","mine him, he hath mare, of it but my fortuess me dr \n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","Temperature 1.2:\n","Advanced generation with seed: 'shall i compare thee to a summer's day thou art'...\n","Progress: 0/400 characters generated...\n","Progress: 100/400 characters generated...\n","Progress: 200/400 characters generated...\n","Progress: 300/400 characters generated...\n","Shall i compare thee to a summer's day thou art. our thy full my way,â€_st \n","remaims. too; to groy. let your aar, hum. had not bollien ded aver xraixed \n","need, droneâ€, in this, mastipe, but ever everway to reptâ€ors. â€ air, why this \n","acque that persuse are now, nor of pent me two boings striens cain writhing my \n","give now. i should loven my antony. iull now gentle dest creai puy (snieving \n","ehumagâ€™d bratted me? that) you knowlested forâ€™stixt i if \n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","Advanced Seed: 'romeo, romeo, wherefore art thou romeo deny thy'\n","------------------------------------------------------------\n","\n","Temperature 0.3:\n","Advanced generation with seed: 'romeo, romeo, wherefore art thou romeo deny thy'...\n","Progress: 0/400 characters generated...\n","Progress: 100/400 characters generated...\n","Progress: 200/400 characters generated...\n","Progress: 300/400 characters generated...\n","Romeo, romeo, wherefore art thou romeo deny thy hand. [_exit. _] scene iii. \n","parolandria. officer of the hand. cleopatra. i make the some and was that thou \n","shall so the give of the man, the hand he with your sum thou say the many, \n","what, i shall was that the man that the tongue the hand you have may that have \n","his man so this shall have beauty, and the thing the great all in the stand \n","mine his hand that the hand the same shall so w \n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","Temperature 0.7:\n","Advanced generation with seed: 'romeo, romeo, wherefore art thou romeo deny thy'...\n","Progress: 0/400 characters generated...\n","Progress: 100/400 characters generated...\n","Progress: 200/400 characters generated...\n","Progress: 300/400 characters generated...\n","Romeo, romeo, wherefore art thou romeo deny thy monsition of thee. rosalind. \n","that the dole melilled him, and to hour, your love? duke mindes. shall tell my \n","messenger? countess. make her hand pelide, for my plant again, for her wit he \n","had of on the braith; to thought. duke say. i well have that my world adung as \n","my aster that he would good tawar, and love of a some alabition thou doth \n","should left as with a into spanting his p \n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","Temperature 1.2:\n","Advanced generation with seed: 'romeo, romeo, wherefore art thou romeo deny thy'...\n","Progress: 0/400 characters generated...\n","Progress: 100/400 characters generated...\n","Progress: 200/400 characters generated...\n","Progress: 300/400 characters generated...\n","Romeo, romeo, wherefore art thou romeo deny thy huns? charmian. i love no never \n","procedent and my pause, his senderâ€™s loveds upon hess my lovâ€™d quess. iâ€™d \n","dajeen yours. thou that, consiner. _ rosalind. nubind against dromios. have \n","comes his palutionâ€™s nest do profesned. pairâ€™d? _ to keep praises shall to \n","mayâ€™s, pharmor. flalâ€™s on my lecs i kemy dexaim. iâ€™rleque when his marty, and \n","again, mine mine, sinch aâ€™enel ugrong burgin! by \n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","Advanced Seed: 'all the world's a stage and all the men and women'\n","------------------------------------------------------------\n","\n","Temperature 0.3:\n","Advanced generation with seed: 'all the world's a stage and all the men and women'...\n","Progress: 0/400 characters generated...\n","Progress: 100/400 characters generated...\n","Progress: 200/400 characters generated...\n","Progress: 300/400 characters generated...\n","All the world's a stage and all the men and women. cleopatra. i make the prople \n","and a more that the man of shore, the leave the strong the hand and shall shall \n","so shall shall will thou shall will should for an the beauty, when thou part \n","they are my distress but the dear the rest thought, and make with the man to \n","the should the stand. cleopatra. what a sent and will that with the love of \n","him, and my many son the stand of my stound, \n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","Temperature 0.7:\n","Advanced generation with seed: 'all the world's a stage and all the men and women'...\n","Progress: 0/400 characters generated...\n","Progress: 100/400 characters generated...\n","Progress: 200/400 characters generated...\n","Progress: 300/400 characters generated...\n","All the world's a stage and all the men and women? silvius. thou knows better \n","heart honesty, didst plession look. that that a most angelf betwing my can once \n","from with my life, then what there lies my fail, in is her shall. and is thy \n","marrect that be i starn of i me have to should palled the homest do the son to \n","dromio the feather, that â€™tis i marches of thy do none. antipholus of syracuse. \n","why, thou part, what he can tomes and in \n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","Temperature 1.2:\n","Advanced generation with seed: 'all the world's a stage and all the men and women'...\n","Progress: 0/400 characters generated...\n","Progress: 100/400 characters generated...\n","Progress: 200/400 characters generated...\n","Progress: 300/400 characters generated...\n","All the world's a stage and all the men and women. orlando. sir? rosalind. \n","though herein yourself, stronging iloys: i live, which althortaged her rescone \n","you, bound; me. atily her mozk usyâ€™er out one vurnot duch who youngâ€™d like \n","away! laques. why. of brom when darrin, [_ese-forber must. [_tidias. brap; \n","satafce two thy geadâ€™st lanch oâ€™ ntue stores as shall have rasurce prignaad \n","blorgent is. [_exeunt clown; astippah. alexand \n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","======================================================================\n","ARCHITECTURE COMPARISON: BASIC vs ADVANCED\n","======================================================================\n","\n","BASIC ARCHITECTURE:\n","   â€¢ Single direction LSTM\n","   â€¢ 2 LSTM layers (128 units each)\n","   â€¢ Basic dropout (0.2)\n","   â€¢ Simple embedding (50 dim)\n","   â€¢ Faster training, less memory\n","   â€¢ Good for quick results\n","\n","ADVANCED ARCHITECTURE:\n","   â€¢ Bidirectional LSTM\n","   â€¢ 3 LSTM layers (256, 256, 128 units)\n","   â€¢ Advanced dropout (0.3)\n","   â€¢ Larger embedding (100 dim)\n","   â€¢ Additional dense layer\n","   â€¢ Learning rate scheduling\n","   â€¢ Better context understanding\n","   â€¢ Richer vocabulary and style\n","\n","ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰\n","SCRIPT EXECUTION COMPLETED!\n","ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰\n","\n","Model files saved:\n","   â€¢ basic_shakespeare_model.h5\n","   â€¢ advanced_shakespeare_model.h5\n","\n","Happy Shakespearean text generating!\n"]}]}]}